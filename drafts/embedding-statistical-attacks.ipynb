{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b24548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolas/miniconda3/envs/py313/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dimension: 384\n",
      "Created 8 embeddings of dimension 384\n",
      "=== NEAREST NEIGHBOR ATTACK ===\n",
      "\n",
      "Target: John Doe's SSN is 123-45-6789\n",
      "Best match: SSN: 444-55-6666\n",
      "Similarity: 0.6694\n",
      "\n",
      "Target: Credit card 4532-1234-5678-9012\n",
      "Best match: Visa card 4111-1111-1111-1111\n",
      "Similarity: 0.7817\n",
      "\n",
      "Target: Password: MyS3cr3tP@ssw0rd!\n",
      "Best match: My password is P@ssw0rd\n",
      "Similarity: 0.7289\n",
      "\n",
      "Target: API key: sk-1234567890abcdef\n",
      "Best match: SSN: 444-55-6666\n",
      "Similarity: 0.3517\n",
      "\n",
      "Target: Salary: $120,000 per year\n",
      "Best match: Makes $150,000 per year\n",
      "Similarity: 0.7349\n",
      "\n",
      "Target: Medical diagnosis: diabetes type 2\n",
      "Best match: Patient has diabetes\n",
      "Similarity: 0.6339\n",
      "\n",
      "Target: Phone: 555-123-4567\n",
      "Best match: Social security number 111-22-3333\n",
      "Similarity: 0.5628\n",
      "\n",
      "Target: Email: john.doe@example.com\n",
      "Best match: My password is P@ssw0rd\n",
      "Similarity: 0.3032\n",
      "\n",
      "=== TOKEN PROBING ATTACK ===\n",
      "\n",
      "Analyzing: John Doe's SSN is 123-45-6789\n",
      "Detected tokens:\n",
      "  - 'SSN' (similarity: 0.610)\n",
      "  - '123-45-6789' (similarity: 0.427)\n",
      "  - 'John' (similarity: 0.446)\n",
      "  - '4532' (similarity: 0.304)\n",
      "\n",
      "Analyzing: Credit card 4532-1234-5678-9012\n",
      "Detected tokens:\n",
      "  - '123-45-6789' (similarity: 0.563)\n",
      "  - 'credit' (similarity: 0.440)\n",
      "  - 'card' (similarity: 0.493)\n",
      "  - '4532' (similarity: 0.531)\n",
      "\n",
      "Analyzing: Password: MyS3cr3tP@ssw0rd!\n",
      "Detected tokens:\n",
      "  - 'SSN' (similarity: 0.381)\n",
      "  - 'password' (similarity: 0.561)\n",
      "\n",
      "Analyzing: API key: sk-1234567890abcdef\n",
      "Detected tokens:\n",
      "  - 'API' (similarity: 0.440)\n",
      "\n",
      "Analyzing: Salary: $120,000 per year\n",
      "Detected tokens:\n",
      "  - 'salary' (similarity: 0.620)\n",
      "  - '$120,000' (similarity: 0.680)\n",
      "\n",
      "Analyzing: Medical diagnosis: diabetes type 2\n",
      "Detected tokens:\n",
      "  - 'diabetes' (similarity: 0.631)\n",
      "  - 'diagnosis' (similarity: 0.430)\n",
      "\n",
      "Analyzing: Phone: 555-123-4567\n",
      "Detected tokens:\n",
      "  - '123-45-6789' (similarity: 0.659)\n",
      "  - '4532' (similarity: 0.386)\n",
      "\n",
      "Analyzing: Email: john.doe@example.com\n",
      "Detected tokens:\n",
      "  - 'John' (similarity: 0.513)\n",
      "  - 'Doe' (similarity: 0.366)\n",
      "\n",
      "=== PATTERN MATCHING ATTACK ===\n",
      "\n",
      "Original: John Doe's SSN is 123-45-6789\n",
      "Best reconstruction: SSN 156-54-7046\n",
      "Similarity: 0.7385\n",
      "\n",
      "Original: Credit card 4532-1234-5678-9012\n",
      "Best reconstruction: Credit card 6122-4957-8438-1578\n",
      "Similarity: 0.9170\n",
      "\n",
      "Original: Password: MyS3cr3tP@ssw0rd!\n",
      "Best reconstruction: Password: XXXXXXXX\n",
      "Similarity: 0.6362\n",
      "\n",
      "=== CATEGORY DETECTION ===\n",
      "\n",
      "Text: John Doe's SSN is 123-45-6789\n",
      "Detected category: SSN-like (confidence: 0.634)\n",
      "\n",
      "Text: Credit card 4532-1234-5678-9012\n",
      "Detected category: Financial (confidence: 0.744)\n",
      "\n",
      "Text: Password: MyS3cr3tP@ssw0rd!\n",
      "Detected category: Credentials (confidence: 0.494)\n",
      "\n",
      "Text: API key: sk-1234567890abcdef\n",
      "Detected category: Credentials (confidence: 0.678)\n",
      "\n",
      "Text: Salary: $120,000 per year\n",
      "Detected category: SSN-like (confidence: 0.180)\n",
      "\n",
      "Text: Medical diagnosis: diabetes type 2\n",
      "Detected category: Medical (confidence: 0.423)\n",
      "\n",
      "Text: Phone: 555-123-4567\n",
      "Detected category: Financial (confidence: 0.440)\n",
      "\n",
      "Text: Email: john.doe@example.com\n",
      "Detected category: Financial (confidence: 0.231)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 214\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Reduce to 2D for visualization\u001b[39;00m\n\u001b[1;32m    213\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m embeddings_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m    217\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py313/lib/python3.13/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/py313/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py313/lib/python3.13/site-packages/sklearn/manifold/_t_sne.py:1177\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/miniconda3/envs/py313/lib/python3.13/site-packages/sklearn/manifold/_t_sne.py:862\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "# Embedding Inversion Attack Demonstration\n",
    "# This notebook shows how embeddings can leak sensitive information\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup and Create Embeddings\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Sensitive documents to embed\n",
    "sensitive_texts = [\n",
    "    \"John Doe's SSN is 123-45-6789\",\n",
    "    \"Credit card 4532-1234-5678-9012\",\n",
    "    \"Password: MyS3cr3tP@ssw0rd!\",\n",
    "    \"API key: sk-1234567890abcdef\",\n",
    "    \"Salary: $120,000 per year\",\n",
    "    \"Medical diagnosis: diabetes type 2\",\n",
    "    \"Phone: 555-123-4567\",\n",
    "    \"Email: john.doe@example.com\"\n",
    "]\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = model.encode(sensitive_texts)\n",
    "print(f\"Created {len(embeddings)} embeddings of dimension {embeddings.shape[1]}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Attack Method 1: Nearest Neighbor Attack\n",
    "# If an attacker has access to a reference dataset, they can find similar texts\n",
    "\n",
    "# %%\n",
    "# Simulate attacker's reference dataset\n",
    "reference_texts = [\n",
    "    # SSN patterns\n",
    "    \"My SSN is 987-65-4321\",\n",
    "    \"Social security number 111-22-3333\",\n",
    "    \"SSN: 444-55-6666\",\n",
    "    # Credit card patterns\n",
    "    \"Visa card 4111-1111-1111-1111\",\n",
    "    \"Credit card number 5500-0000-0000-0004\",\n",
    "    \"Card: 3700-0000-0000-002\",\n",
    "    # Password patterns\n",
    "    \"Password: SecretPass123!\",\n",
    "    \"My password is P@ssw0rd\",\n",
    "    \"Login: Admin123!\",\n",
    "    # Salary patterns\n",
    "    \"Annual salary $95,000\",\n",
    "    \"Makes $150,000 per year\",\n",
    "    \"Salary: $75,000 annually\",\n",
    "    # Medical patterns\n",
    "    \"Diagnosed with hypertension\",\n",
    "    \"Patient has diabetes\",\n",
    "    \"Medical condition: asthma\"\n",
    "]\n",
    "\n",
    "reference_embeddings = model.encode(reference_texts)\n",
    "\n",
    "# Find nearest neighbors for each sensitive embedding\n",
    "print(\"=== NEAREST NEIGHBOR ATTACK ===\\n\")\n",
    "for i, (text, emb) in enumerate(zip(sensitive_texts, embeddings)):\n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity([emb], reference_embeddings)[0]\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    \n",
    "    print(f\"Target: {text}\")\n",
    "    print(f\"Best match: {reference_texts[best_match_idx]}\")\n",
    "    print(f\"Similarity: {similarities[best_match_idx]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Attack Method 2: Token Probing Attack\n",
    "# Test if specific sensitive tokens are present in the text\n",
    "\n",
    "# %%\n",
    "# Tokens to probe for\n",
    "probe_tokens = [\n",
    "    \"SSN\", \"123-45-6789\", \"John\", \"Doe\",\n",
    "    \"credit\", \"card\", \"4532\", \"password\",\n",
    "    \"salary\", \"$120,000\", \"diabetes\", \"API\",\n",
    "    \"secret\", \"medical\", \"diagnosis\"\n",
    "]\n",
    "\n",
    "# Create probe embeddings\n",
    "probe_embeddings = model.encode(probe_tokens)\n",
    "\n",
    "print(\"=== TOKEN PROBING ATTACK ===\\n\")\n",
    "# For each sensitive text, check which tokens have high similarity\n",
    "for i, (text, emb) in enumerate(zip(sensitive_texts, embeddings)):\n",
    "    print(f\"Analyzing: {text}\")\n",
    "    \n",
    "    # Calculate similarities with all probes\n",
    "    similarities = cosine_similarity([emb], probe_embeddings)[0]\n",
    "    \n",
    "    # Find high-similarity tokens\n",
    "    high_sim_indices = np.where(similarities > 0.3)[0]\n",
    "    if len(high_sim_indices) > 0:\n",
    "        print(\"Detected tokens:\")\n",
    "        for idx in high_sim_indices:\n",
    "            print(f\"  - '{probe_tokens[idx]}' (similarity: {similarities[idx]:.3f})\")\n",
    "    print()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Attack Method 3: Gradient-Based Inversion (Conceptual)\n",
    "# With model access, we can try to reconstruct text that produces similar embeddings\n",
    "\n",
    "# %%\n",
    "# This is a simplified demonstration of the concept\n",
    "# In practice, this would require access to the model's gradients\n",
    "\n",
    "def measure_embedding_leakage(original_text, embedding, model, num_probes=100):\n",
    "    \"\"\"\n",
    "    Measure how much information leaks by testing random modifications\n",
    "    \"\"\"\n",
    "    # Generate variations of common sensitive patterns\n",
    "    patterns = [\n",
    "        \"SSN XXX-XX-XXXX\",\n",
    "        \"Credit card XXXX-XXXX-XXXX-XXXX\",\n",
    "        \"Password: XXXXXXXX\",\n",
    "        \"Salary $XXX,XXX\",\n",
    "        \"Diagnosis: XXXXX\"\n",
    "    ]\n",
    "    \n",
    "    best_match = None\n",
    "    best_similarity = -1\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        # Test different values for the pattern\n",
    "        for _ in range(num_probes // len(patterns)):\n",
    "            # Generate a random instantiation\n",
    "            test_text = pattern\n",
    "            if \"SSN\" in pattern:\n",
    "                test_text = test_text.replace(\"XXX-XX-XXXX\", \n",
    "                    f\"{np.random.randint(100,999)}-{np.random.randint(10,99)}-{np.random.randint(1000,9999)}\")\n",
    "            elif \"card\" in pattern:\n",
    "                test_text = test_text.replace(\"XXXX-XXXX-XXXX-XXXX\",\n",
    "                    f\"{np.random.randint(1000,9999)}-{np.random.randint(1000,9999)}-{np.random.randint(1000,9999)}-{np.random.randint(1000,9999)}\")\n",
    "            elif \"Salary\" in pattern:\n",
    "                test_text = test_text.replace(\"XXX,XXX\",\n",
    "                    f\"{np.random.randint(50,200)},{np.random.randint(0,999):03d}\")\n",
    "            \n",
    "            # Get embedding and compare\n",
    "            test_embedding = model.encode([test_text])[0]\n",
    "            similarity = 1 - cosine(embedding, test_embedding)\n",
    "            \n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match = test_text\n",
    "    \n",
    "    return best_match, best_similarity\n",
    "\n",
    "print(\"=== PATTERN MATCHING ATTACK ===\\n\")\n",
    "for text, emb in zip(sensitive_texts[:3], embeddings[:3]):  # Demo on first 3\n",
    "    reconstructed, similarity = measure_embedding_leakage(text, emb, model)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Best reconstruction: {reconstructed}\")\n",
    "    print(f\"Similarity: {similarity:.4f}\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Attack Method 4: Embedding Space Analysis\n",
    "# Analyze the geometry of embeddings to infer properties\n",
    "\n",
    "# %%\n",
    "# Calculate centroid of different types of sensitive data\n",
    "ssn_embeddings = embeddings[0:1]  # SSN example\n",
    "financial_embeddings = embeddings[1:2]  # Credit card\n",
    "credential_embeddings = embeddings[2:4]  # Password and API key\n",
    "pii_embeddings = embeddings[4:8]  # Other PII\n",
    "\n",
    "# Create \"category vectors\" by averaging similar types\n",
    "categories = {\n",
    "    \"SSN-like\": model.encode([\"SSN 000-00-0000\", \"Social Security 111-11-1111\"]).mean(axis=0),\n",
    "    \"Financial\": model.encode([\"Credit card 0000-0000-0000-0000\", \"Bank account 12345\"]).mean(axis=0),\n",
    "    \"Credentials\": model.encode([\"Password: xxxx\", \"API key: xxxx\"]).mean(axis=0),\n",
    "    \"Medical\": model.encode([\"Diagnosis: condition\", \"Medical record\"]).mean(axis=0)\n",
    "}\n",
    "\n",
    "print(\"=== CATEGORY DETECTION ===\\n\")\n",
    "for text, emb in zip(sensitive_texts, embeddings):\n",
    "    print(f\"Text: {text}\")\n",
    "    \n",
    "    # Find closest category\n",
    "    best_category = None\n",
    "    best_sim = -1\n",
    "    for cat_name, cat_emb in categories.items():\n",
    "        sim = 1 - cosine(emb, cat_emb)\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_category = cat_name\n",
    "    \n",
    "    print(f\"Detected category: {best_category} (confidence: {best_sim:.3f})\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Visualization of Information Leakage\n",
    "\n",
    "# %%\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Combine sensitive and reference embeddings\n",
    "all_embeddings = np.vstack([embeddings, reference_embeddings])\n",
    "all_texts = sensitive_texts + reference_texts\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot sensitive texts in red\n",
    "plt.scatter(embeddings_2d[:len(sensitive_texts), 0], \n",
    "           embeddings_2d[:len(sensitive_texts), 1], \n",
    "           c='red', s=100, label='Sensitive Data', marker='o')\n",
    "\n",
    "# Plot reference texts in blue\n",
    "plt.scatter(embeddings_2d[len(sensitive_texts):, 0], \n",
    "           embeddings_2d[len(sensitive_texts):, 1], \n",
    "           c='blue', s=100, label='Reference Data', marker='^')\n",
    "\n",
    "# Add labels for sensitive texts\n",
    "for i, txt in enumerate(sensitive_texts):\n",
    "    plt.annotate(txt[:20] + \"...\", \n",
    "                (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=8, color='darkred')\n",
    "\n",
    "plt.title(\"Embedding Space Visualization - Sensitive Data Clustering\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Summary: What Can Be Recovered\n",
    "\n",
    "# %%\n",
    "print(\"=== EMBEDDING INVERSION ATTACK SUMMARY ===\\n\")\n",
    "\n",
    "print(\"1. PATTERN DETECTION:\")\n",
    "print(\"   - Can detect the TYPE of sensitive data (SSN, credit card, password)\")\n",
    "print(\"   - Can narrow down to specific patterns and formats\")\n",
    "\n",
    "print(\"\\n2. PARTIAL RECONSTRUCTION:\")\n",
    "print(\"   - Can identify presence of specific tokens or words\")\n",
    "print(\"   - Can approximate numerical ranges (e.g., salary brackets)\")\n",
    "\n",
    "print(\"\\n3. SIMILARITY MATCHING:\")\n",
    "print(\"   - With a reference dataset, can find very similar texts\")\n",
    "print(\"   - Can identify individuals if their data appears in training sets\")\n",
    "\n",
    "print(\"\\n4. CATEGORY INFERENCE:\")\n",
    "print(\"   - Can determine the general category of information\")\n",
    "print(\"   - Can distinguish between medical, financial, credential data\")\n",
    "\n",
    "print(\"\\n⚠️  CONCLUSION: Embeddings are NOT safe for sensitive data!\")\n",
    "print(\"Even without the original text, attackers can extract significant information.\")\n",
    "print(\"\\n✅ This is why encrypted vector databases are essential for sensitive data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
