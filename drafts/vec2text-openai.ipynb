{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Embedding Inversion using vec2text with OpenAI Embeddings\n",
    "# This notebook demonstrates inverting OpenAI's text-embedding-ada-002 embeddings back to text\n",
    "\n",
    "\n",
    "import vec2text\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Constants\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Load the pre-trained corrector\n",
    "print(f\"Loading vec2text corrector for OpenAI {embedding_model}...\")\n",
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db743a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Diverse test corpus including sensitive information\n",
    "test_corpus = [  \n",
    "    # Sensitive Information (to test security implications)\n",
    "    \"My social security number is 818-88-8118\",\n",
    "    \"Password for admin account is SecurePass123!\",\n",
    "    \"Credit card number 4532-1234-5678-9012 expires next month\",\n",
    "    \"API key for production: sk-proj-1234567890abcdef\",\n",
    "    \"Bank account routing number 021000021 checking 1234567890\",\n",
    "    \n",
    "    # Medical Information\n",
    "    \"Patient diagnosed with Type 2 diabetes, prescribed metformin\",\n",
    "    \"Blood test results show cholesterol level of 277 mg/dL\",\n",
    "    \n",
    "    # Personal Information\n",
    "    \"John Doe lives at 1 World Trade Center, New York, NY 10007\",\n",
    "    \"Phone number +1(212) 653-0688; email info@cyborg.co\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate OpenAI Embeddings\n",
    "\n",
    "def get_embeddings_openai(text_list) -> torch.Tensor:\n",
    "    \"\"\"Get embeddings from OpenAI API (batched for efficiency)\"\"\"\n",
    "    print(f\"Generating embeddings for {len(text_list)} texts...\")\n",
    "    \n",
    "    batches = math.ceil(len(text_list) / 128)\n",
    "    outputs = []\n",
    "    for batch in range(batches):\n",
    "        text_list_batch = text_list[batch * 128 : (batch + 1) * 128]\n",
    "        response = client.embeddings.create(\n",
    "            input=text_list_batch,\n",
    "            model=embedding_model,\n",
    "            encoding_format=\"float\",\n",
    "        )\n",
    "        outputs.extend([e.embedding for e in response.data])\n",
    "    return torch.tensor(outputs)\n",
    "\n",
    "# Get embeddings as torch tensor\n",
    "embeddings = get_embeddings_openai(test_corpus)\n",
    "print(f\"\\nEmbedding shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "# Move to same device as the model\n",
    "# Check where the corrector model is\n",
    "if hasattr(corrector, 'device'):\n",
    "    embeddings = embeddings.to(corrector.device)\n",
    "elif hasattr(corrector, 'model') and hasattr(corrector.model, 'device'):\n",
    "    embeddings = embeddings.to(corrector.model.device)\n",
    "elif torch.backends.mps.is_available():\n",
    "    # On Apple Silicon\n",
    "    embeddings = embeddings.to('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    embeddings = embeddings.cuda()\n",
    "    \n",
    "print(f\"Embeddings on device: {embeddings.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd955eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert embeddings\n",
    "results = []\n",
    "\n",
    "for i, (text, embedding) in enumerate(zip(test_corpus, embeddings)):\n",
    "    print(f\"Embedding #{i+1}:\")\n",
    "    print(f\"Original Text: {text}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Invert single embedding (need to add batch dimension)\n",
    "    reconstructed_list = vec2text.invert_embeddings(\n",
    "        embeddings=embedding.unsqueeze(0),  # Add batch dimension\n",
    "        corrector=corrector,\n",
    "        num_steps=20,  # More steps = better quality\n",
    "        sequence_beam_width=1,  # Increase for better quality but slower\n",
    "    )\n",
    "    reconstructed = reconstructed_list[0]  # Get first (only) result\n",
    "    \n",
    "    inversion_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Reconstructed: {reconstructed}\")\n",
    "    \n",
    "    # Calculate similarity\n",
    "    orig_emb_cpu = embedding.cpu()\n",
    "    recon_emb = get_embeddings_openai([reconstructed])[0]\n",
    "    similarity = torch.nn.functional.cosine_similarity(orig_emb_cpu, recon_emb, dim=0).item()\n",
    "    \n",
    "    print(f\"Similarity: {similarity:.4f}\")\n",
    "    print(f\"Inversion time: {inversion_time:.2f}s\")\n",
    "    \n",
    "    # Check for exact match\n",
    "    exact_match = text.lower().strip() == reconstructed.lower().strip()\n",
    "    print(f\"Exact match: {exact_match}\")\n",
    "    \n",
    "    results.append({\n",
    "        'original': text,\n",
    "        'reconstructed': reconstructed,\n",
    "        'similarity': similarity,\n",
    "        'time': inversion_time,\n",
    "        'exact_match': exact_match,\n",
    "        'length_diff': abs(len(text) - len(reconstructed))\n",
    "    })\n",
    "    \n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3623d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
