{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b404d7",
   "metadata": {},
   "source": [
    "# CyborgDB + Vec2Text Vulnerability Demonstration\n",
    "\n",
    "This notebook shows how sensitive data stored in CyborgDB **cannot** be reconstructed using vec2text\n",
    " \n",
    "### Attack Chain:\n",
    "1. Sensitive texts → OpenAI embeddings → CyborgDB storage\n",
    "2. Extract encrypted embeddings from PostgreSQL database\n",
    "3. Use vec2text to *attempt* reconstruct original sensitive text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import secrets\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import vec2text\n",
    "import torch\n",
    "\n",
    "# OpenAI setup\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Load vec2text corrector for inversion\n",
    "print(f\"Loading vec2text corrector for OpenAI {embedding_model}...\")\n",
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyborgdb_lite import Client, DBConfig, IndexIVFFlat\n",
    "\n",
    "# CyborgDB setup\n",
    "cyborgdb_client = Client(\n",
    "    DBConfig(location=\"postgres\", connection_string=\"host=localhost port=5432 dbname=postgres\", table_name=\"index\"),\n",
    "    DBConfig(location=\"postgres\", connection_string=\"host=localhost port=5432 dbname=postgres\", table_name=\"items\"),\n",
    "    DBConfig(location=\"postgres\", connection_string=\"host=localhost port=5432 dbname=postgres\", table_name=\"config\"),\n",
    ")\n",
    "\n",
    "encrypted_index = cyborgdb_client.create_index(\n",
    "    index_name=f\"cyborgdb-vec2text-demo-{secrets.token_hex(8)}\",\n",
    "    index_key=secrets.token_bytes(32),\n",
    "    index_config=IndexIVFFlat(\n",
    "        dimension=1536,\n",
    "        n_lists=128\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sensitive Test Corpus (same as vec2text demo)\n",
    "\n",
    "sensitive_documents = [\n",
    "    # Financial/Identity Information\n",
    "    \"My social security number is 818-88-8118\",\n",
    "    \"Password for admin account is SecurePass123!\",\n",
    "    \"Credit card number 4532-1234-5678-9012 expires next month\",\n",
    "    \"API key for production: sk-proj-1234567890abcdef\",\n",
    "    \"Bank account routing number 021000021 checking 1234567890\",\n",
    "    \n",
    "    # Medical Information\n",
    "    \"Patient diagnosed with Type 2 diabetes, prescribed metformin\",\n",
    "    \"Blood test results show cholesterol level of 277 mg/dL\",\n",
    "    \n",
    "    # Personal Information\n",
    "    \"John Doe lives at 1 World Trade Center, New York, NY 10007\",\n",
    "    \"Phone number +1(212) 653-0688; email info@cyborg.co\",\n",
    "]\n",
    "\n",
    "print(f\"Testing with {len(sensitive_documents)} sensitive documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate OpenAI Embeddings and Store in ChromaDB\n",
    "\n",
    "def get_embeddings_openai(text_list):\n",
    "    \"\"\"Get embeddings from OpenAI API\"\"\"\n",
    "    print(f\"Generating embeddings for {len(text_list)} texts...\")\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text_list,\n",
    "        model=embedding_model,\n",
    "        encoding_format=\"float\",\n",
    "    )\n",
    "    return [e.embedding for e in response.data]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = get_embeddings_openai(sensitive_documents)\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\")\n",
    "\n",
    "# Construct items\n",
    "items = [\n",
    "    {\n",
    "        \"id\": f\"sensitive_doc_{i}\",\n",
    "        \"embedding\": embedding,\n",
    "        \"contents\": doc\n",
    "    }\n",
    "    for i, (doc, embedding) in enumerate(zip(sensitive_documents, embeddings))\n",
    "]\n",
    "\n",
    "# Store in ChromaDB\n",
    "encrypted_index.upsert(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extract Embeddings from CyborgDB PostgreSQL Database\n",
    "\n",
    "print(\"\\n=== EXTRACTING EMBEDDINGS FROM CYBORGDB POSTGRESQL BACKEND ===\")\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# Connect directly to PostgreSQL\n",
    "try:\n",
    "    pg_client = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"cyborgdb\",  # Adjust database name as needed\n",
    "        user=\"postgres\",      # Adjust username as needed\n",
    "        password=\"password\",  # Adjust password as needed\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = pg_client.cursor(cursor_factory=RealDictCursor)\n",
    "    print(f\"✅ Connected to PostgreSQL server\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to PostgreSQL: {e}\")\n",
    "    print(\"Please ensure PostgreSQL is running and adjust connection parameters\")\n",
    "    raise\n",
    "\n",
    "# Explore database schema\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public' \n",
    "    ORDER BY table_name;\n",
    "\"\"\")\n",
    "tables = cursor.fetchall()\n",
    "print(f\"Found {len(tables)} tables in database:\")\n",
    "for table in tables:\n",
    "    print(f\"  - {table['table_name']}\")\n",
    "\n",
    "# Look for tables related to our index\n",
    "index_tables = [t['table_name'] for t in tables if 'cyborgdb' in t['table_name'].lower() or 'vec2text' in t['table_name'].lower() or 'embedding' in t['table_name'].lower()]\n",
    "print(f\"\\nTables related to our index: {index_tables}\")\n",
    "\n",
    "# If no specific tables found, look for vector/embedding related tables\n",
    "if not index_tables:\n",
    "    vector_tables = [t['table_name'] for t in tables if any(keyword in t['table_name'].lower() for keyword in ['vector', 'embedding', 'index', 'item', 'metadata'])]\n",
    "    print(f\"Vector-related tables: {vector_tables}\")\n",
    "    index_tables = vector_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35933773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Convert to PyTorch & Invert Each Embedding\n",
    "\n",
    "print(\"\\n=== RUNNING VEC2TEXT INVERSION ON EXTRACTED EMBEDDINGS ===\")\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "embeddings_tensor = torch.tensor(extracted_embeddings, dtype=torch.float32)\n",
    "\n",
    "# Move to appropriate device\n",
    "if torch.backends.mps.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.to('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.cuda()\n",
    "\n",
    "print(f\"Embeddings tensor shape: {embeddings_tensor.shape}\")\n",
    "print(f\"Device: {embeddings_tensor.device}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INVERSION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (original_doc, embedding) in enumerate(zip(extracted_documents, embeddings_tensor)):\n",
    "    print(f\"\\nDocument #{i+1}:\")\n",
    "    print(f\"\\nOriginal (from database): {original_doc}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Invert embedding\n",
    "    reconstructed_list = vec2text.invert_embeddings(\n",
    "        embeddings=embedding.unsqueeze(0),  # Add batch dimension\n",
    "        corrector=corrector,\n",
    "        num_steps=20,\n",
    "        sequence_beam_width=1,\n",
    "    )\n",
    "    reconstructed = reconstructed_list[0]\n",
    "    \n",
    "    inversion_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Reconstructed: {reconstructed}\")\n",
    "    \n",
    "    # Calculate similarity\n",
    "    orig_emb_cpu = embedding.cpu()\n",
    "    new_emb = get_embeddings_openai([reconstructed])[0]\n",
    "    new_emb_tensor = torch.tensor(new_emb)\n",
    "    similarity = torch.nn.functional.cosine_similarity(orig_emb_cpu, new_emb_tensor, dim=0).item()\n",
    "    \n",
    "    # Check exact match\n",
    "    exact_match = original_doc.lower().strip() == reconstructed.lower().strip()\n",
    "    \n",
    "    print(f\"Similarity: {similarity:.4f}\")\n",
    "    print(f\"Inversion time: {inversion_time:.2f}s\")\n",
    "    print(f\"Exact match: {exact_match}\")\n",
    "    \n",
    "    results.append({\n",
    "        'original': original_doc,\n",
    "        'reconstructed': reconstructed,\n",
    "        'similarity': similarity,\n",
    "        'time': inversion_time,\n",
    "        'exact_match': exact_match,\n",
    "    })\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Summary Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VULNERABILITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_docs = len(results)\n",
    "exact_matches = sum(1 for r in results if r['exact_match'])\n",
    "high_similarity = sum(1 for r in results if r['similarity'] > 0.95)\n",
    "sensitive_recovered = sum(1 for r in results if r['sensitive_recovered'])\n",
    "\n",
    "print(f\"Total documents processed: {total_docs}\")\n",
    "print(f\"Exact reconstructions: {exact_matches} ({exact_matches/total_docs*100:.1f}%)\")\n",
    "print(f\"High similarity (>95%): {high_similarity} ({high_similarity/total_docs*100:.1f}%)\")\n",
    "\n",
    "avg_similarity = np.mean([r['similarity'] for r in results])\n",
    "avg_time = np.mean([r['time'] for r in results])\n",
    "\n",
    "print(f\"Average similarity: {avg_similarity:.4f}\")\n",
    "print(f\"Average inversion time: {avg_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nATTACK CHAIN COMPLETE:\")\n",
    "print(f\"   1. Stored sensitive data in ChromaDB\")\n",
    "print(f\"   2. Extracted embeddings from SQLite database\") \n",
    "print(f\"   3. Reconstructed {sensitive_recovered}/{total_docs} sensitive documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inversion-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
