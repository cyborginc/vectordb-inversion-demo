{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b404d7",
   "metadata": {},
   "source": [
    "# CyborgDB + Vec2Text Vulnerability Demonstration\n",
    "\n",
    "This notebook shows how sensitive data stored in CyborgDB **cannot** be reconstructed using vec2text\n",
    " \n",
    "### Attack Chain:\n",
    "1. Sensitive texts → OpenAI embeddings → CyborgDB storage\n",
    "2. Extract encrypted embeddings from PostgreSQL database\n",
    "3. Use vec2text to *attempt* reconstruct original sensitive text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set up OpenAI embedding & vec2text corrector models\n",
    "\n",
    "import os\n",
    "import vec2text\n",
    "from openai import OpenAI\n",
    "\n",
    "# Environment variable setup\n",
    "def setup_env():\n",
    "    os.environ['OMP_NUM_THREADS'] = '1'\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = '1' \n",
    "    os.environ['MKL_NUM_THREADS'] = '1'\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "    os.environ['DEMO_INDEX_KEY'] = bytes(b'00000000000000000000000000000000').hex()\n",
    "setup_env()\n",
    "\n",
    "# ANSI color codes for live demo\n",
    "class Colors:\n",
    "    RED = '\\033[91m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "def print_colored(text, color=\"\", bold=False):\n",
    "    \"\"\"Print colored text for demo\"\"\"\n",
    "    prefix = Colors.BOLD if bold else \"\"\n",
    "    prefix += getattr(Colors, color.upper(), \"\")\n",
    "    print(f\"{prefix}{text}{Colors.END}\")\n",
    "\n",
    "# OpenAI setup\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Load vec2text corrector for inversion\n",
    "print(f\"Loading vec2text corrector for OpenAI {embedding_model}...\")\n",
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Set up CyborgDB\n",
    "\n",
    "from cyborgdb_lite import Client, DBConfig, IndexIVFFlat\n",
    "\n",
    "# Set up PostgreSQL connection parameters\n",
    "# Make sure to change these to your actual PostgreSQL credentials\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "POSTGRES_PORT = 5432\n",
    "POSTGRES_DB = \"postgres\"\n",
    "POSTGRES_USER = \"nicolas\"\n",
    "POSTGRES_PASSWORD = \"password\"\n",
    "\n",
    "postgres_connection_string = (\n",
    "    f\"host={POSTGRES_HOST} port={POSTGRES_PORT} dbname={POSTGRES_DB} \"\n",
    "    f\"user={POSTGRES_USER} password={POSTGRES_PASSWORD}\"\n",
    ")\n",
    "\n",
    "# CyborgDB setup\n",
    "cyborgdb_client = Client(\n",
    "    DBConfig(location=\"postgres\", connection_string=postgres_connection_string, table_name=\"index_cc_demo\"),\n",
    "    DBConfig(location=\"postgres\", connection_string=postgres_connection_string, table_name=\"items_cc_demo\"),\n",
    "    DBConfig(location=\"postgres\", connection_string=postgres_connection_string, table_name=\"config_cc_demo\"),\n",
    ")\n",
    "\n",
    "# Load and delete existing index if there's a conflict\n",
    "try:\n",
    "    old_index = cyborgdb_client.load_index(\n",
    "        index_name=f\"cyborgdb-vec2text-demo\",\n",
    "        index_key=bytes.fromhex(os.getenv('DEMO_INDEX_KEY')),\n",
    "    )\n",
    "    old_index.delete_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new index\n",
    "encrypted_index = cyborgdb_client.create_index(\n",
    "    index_name=f\"cyborgdb-vec2text-demo\",\n",
    "    index_key=bytes.fromhex(os.getenv('DEMO_INDEX_KEY')),\n",
    "    index_config=IndexIVFFlat(\n",
    "        dimension=1536,\n",
    "        n_lists=128\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define sensitive documents for demo\n",
    "\n",
    "sensitive_documents = [\n",
    "    # Financial/Identity Information\n",
    "    \"My social security number is 818-88-8118\",\n",
    "    \"Password for admin account is SecurePass123!\",\n",
    "    \n",
    "    # Medical Information\n",
    "    \"Patient diagnosed with Type 2 diabetes, prescribed metformin\",\n",
    "    \"Blood test results show cholesterol level of 277 mg/dL\",\n",
    "    \n",
    "    # Personal Information\n",
    "    \"John Doe lives at 1 World Trade Center, New York, NY 10007\",\n",
    "    \"Phone number +1(212) 653-0688; email info@cyborg.co\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate embeddings & store in CyborgDB\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"GENERATING EMBEDDINGS FROM SENSITIVE DOCUMENTS\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "def get_embeddings_openai(text_list):\n",
    "    \"\"\"Get embeddings from OpenAI API\"\"\"\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text_list,\n",
    "        model=embedding_model,\n",
    "        encoding_format=\"float\",\n",
    "    )\n",
    "    return [e.embedding for e in response.data]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = get_embeddings_openai(sensitive_documents)\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\")\n",
    "\n",
    "# Construct items\n",
    "items = [\n",
    "    {\n",
    "        \"id\": f\"sensitive_doc_{i}\",\n",
    "        \"vector\": embedding,\n",
    "        \"contents\": doc\n",
    "    }\n",
    "    for i, (doc, embedding) in enumerate(zip(sensitive_documents, embeddings))\n",
    "]\n",
    "\n",
    "# Store in CyborgDB\n",
    "encrypted_index.upsert(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Extract embeddings from CyborgDB Postgres backend\n",
    "\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"EXTRACTING EMBEDDINGS FROM CYBORGDB POSTGRESQL BACKEND\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Connect to CyborgDB's PostgreSQL database\n",
    "pg_client = psycopg2.connect(\n",
    "    host=POSTGRES_HOST,\n",
    "    database=POSTGRES_DB,\n",
    "    user=POSTGRES_USER,\n",
    "    password=POSTGRES_PASSWORD,\n",
    "    port=POSTGRES_PORT\n",
    ")\n",
    "cursor = pg_client.cursor(cursor_factory=RealDictCursor)\n",
    "\n",
    "# Get a few rows to examine the value column\n",
    "cursor.execute(\"SELECT key, value, index_name FROM index_cc_demo;\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "extracted_embeddings = []\n",
    "n = 0\n",
    "for i, row in enumerate(rows):\n",
    "    value = row['value']\n",
    "    key = row['key']\n",
    "    \n",
    "    if value is not None:\n",
    "        # Convert memory buffer to bytes\n",
    "        if hasattr(value, 'tobytes'):\n",
    "            bytes_data = value.tobytes()\n",
    "        else:\n",
    "            bytes_data = bytes(value)\n",
    "\n",
    "        # Ignore rows too small (< dim & 4B)\n",
    "        if len(bytes_data) < 1536 * 4:\n",
    "            continue\n",
    "        \n",
    "        # Increment counter\n",
    "        n += 1\n",
    "\n",
    "        # Determine if value is encrypted\n",
    "        entropy = -sum(\n",
    "            (bytes_data.count(byte) / len(bytes_data)) * \n",
    "            np.log2(bytes_data.count(byte) / len(bytes_data)) \n",
    "        for byte in set(bytes_data))\n",
    "\n",
    "        if entropy > 7.8 and len(bytes_data) != 1536 * 4:\n",
    "            is_encrypted = True\n",
    "        else: \n",
    "            is_encrypted = False\n",
    "        \n",
    "        if is_encrypted:\n",
    "            # Trim to expected size\n",
    "            expected_length = 1536 * 4\n",
    "            bytes_data = bytes_data[:expected_length]\n",
    "\n",
    "            # Try to interpret as float anyway\n",
    "            embedding_values = np.frombuffer(bytes_data, dtype=np.float32)\n",
    "            extracted_embeddings.append(embedding_values.tolist())\n",
    "\n",
    "            print_colored(f\"Extracted encrypted embedding {n} corresponding to file {key}; length {len(bytes_data)} bytes\", \"GREEN\")\n",
    "        else:\n",
    "            embedding_values = np.frombuffer(bytes_data, dtype=np.float32)\n",
    "            extracted_embeddings.append(embedding_values.tolist())\n",
    "\n",
    "            print_colored(f\"Extracted embedding {n} corresponding to file {key}; {len(embedding_values)} dimensions\", \"RED\")\n",
    "\n",
    "# Print the first embedding as an example\n",
    "if extracted_embeddings:\n",
    "    print_colored(\"\\nFirst extracted embedding:\", bold=True)\n",
    "    print(extracted_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35933773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Convert to PyTorch & invert each embedding\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Convert to PyTorch tensor on accelerated hardware if possible\n",
    "embeddings_tensor = torch.tensor(extracted_embeddings, dtype=torch.float32)\n",
    "if torch.backends.mps.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.to('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    embeddings_tensor = embeddings_tensor.cuda()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print_colored(\"RUNNING EMBEDDING INVERSION\", bold=True)\n",
    "print(\"=\"*80)\n",
    "\n",
    "# for i, (original_doc, embedding) in enumerate(zip(extracted_documents, embeddings_tensor)):\n",
    "for i, (original_doc, embedding) in enumerate(zip(sensitive_documents, embeddings_tensor)):\n",
    "    print_colored(f\"\\nDocument #{i+1}:\", bold=True)\n",
    "    print(f\"\\nOriginal:      \\\"{original_doc}\\\"\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Invert embedding\n",
    "    reconstructed_list = vec2text.invert_embeddings(\n",
    "        embeddings=embedding.unsqueeze(0),  # Add batch dimension\n",
    "        corrector=corrector,\n",
    "        num_steps=4,\n",
    "        sequence_beam_width=1,\n",
    "    )\n",
    "    reconstructed = reconstructed_list[0]\n",
    "    \n",
    "    inversion_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Reconstructed: \\\"{reconstructed}\\\"\")\n",
    "        \n",
    "    # Calculate similarity\n",
    "    if len(reconstructed) > 0:\n",
    "        orig_emb_cpu = embedding.cpu()\n",
    "        new_emb = get_embeddings_openai([reconstructed])[0]\n",
    "        new_emb_tensor = torch.tensor(new_emb)\n",
    "        similarity = torch.nn.functional.cosine_similarity(orig_emb_cpu, new_emb_tensor, dim=0).item()\n",
    "    else:\n",
    "        similarity = 0\n",
    "\n",
    "    # Check exact match\n",
    "    exact_match = original_doc.lower().strip() == reconstructed.lower().strip()\n",
    "\n",
    "    if exact_match:\n",
    "        print_colored(f\"Exact match\", \"RED\", bold=True)\n",
    "    \n",
    "    sim_color = \"RED\" if similarity > 0.99 else \"YELLOW\" if similarity > 0.95 else \"GREEN\"\n",
    "    print_colored(f\"Similarity: {similarity:.4f}\", sim_color, bold=True)\n",
    "    print(f\"Inversion time: {inversion_time:.2f}s\")\n",
    "\n",
    "    results.append({\n",
    "        'original': original_doc,\n",
    "        'reconstructed': reconstructed,\n",
    "        'similarity': similarity,\n",
    "        'time': inversion_time,\n",
    "        'exact_match': exact_match,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Summary Analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print_colored(\"VULNERABILITY SUMMARY\", bold=True)\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "total_docs = len(results)\n",
    "exact_matches = sum(1 for r in results if r['exact_match'])\n",
    "high_similarity = sum(1 for r in results if r['similarity'] > 0.95)\n",
    "\n",
    "print(f\"Total documents processed: {total_docs}\")\n",
    "print(f\"Exact reconstructions: {exact_matches} ({exact_matches/total_docs*100:.1f}%)\")\n",
    "print(f\"High similarity (>95%): {high_similarity} ({high_similarity/total_docs*100:.1f}%)\")\n",
    "\n",
    "avg_similarity = np.mean([r['similarity'] for r in results])\n",
    "avg_time = np.mean([r['time'] for r in results])\n",
    "sim_color = \"RED\" if avg_similarity > 0.99 else \"YELLOW\" if avg_similarity > 0.95 else \"GREEN\"\n",
    "\n",
    "print_colored(f\"Average similarity: {avg_similarity*100:.2f}%\", sim_color, bold=True)\n",
    "print(f\"Average inversion time: {avg_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inversion-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
